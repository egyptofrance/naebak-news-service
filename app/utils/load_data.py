"""
Ø£Ø¯Ø§Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± - Ù…Ø´Ø±ÙˆØ¹ Ù†Ø§Ø¦Ø¨Ùƒ
"""
from app.models import (
    db, NewsCategory, NewsTag, NewsItem, NewsComment, 
    NewsStats, NewsSettings
)
from app.data.initial_data import (
    NEWS_CATEGORIES, NEWS_TAGS, SAMPLE_NEWS, SAMPLE_COMMENTS,
    NEWS_SETTINGS, SAMPLE_STATS
)
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


def load_news_categories():
    """ØªØ­Ù…ÙŠÙ„ ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"""
    try:
        logger.info("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")
        
        for category_data in NEWS_CATEGORIES:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ØªØµÙ†ÙŠÙ
            existing = NewsCategory.query.filter_by(name=category_data['name']).first()
            if not existing:
                category = NewsCategory(
                    name=category_data['name'],
                    name_en=category_data['name_en'],
                    description=category_data['description'],
                    description_en=category_data['description_en'],
                    icon=category_data['icon'],
                    color=category_data['color'],
                    display_order=category_data['display_order']
                )
                db.session.add(category)
                logger.info(f"ØªÙ… Ø¥Ø¶Ø§ÙØ© ØªØµÙ†ÙŠÙ: {category.name}")
        
        db.session.commit()
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(NEWS_CATEGORIES)} ØªØµÙ†ÙŠÙ Ø£Ø®Ø¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {str(e)}")
        db.session.rollback()
        raise


def load_news_tags():
    """ØªØ­Ù…ÙŠÙ„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"""
    try:
        logger.info("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")
        
        for tag_data in NEWS_TAGS:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¹Ù„Ø§Ù…Ø©
            existing = NewsTag.query.filter_by(name=tag_data['name']).first()
            if not existing:
                tag = NewsTag(
                    name=tag_data['name'],
                    name_en=tag_data['name_en'],
                    description=tag_data['description'],
                    color=tag_data['color']
                )
                db.session.add(tag)
                logger.info(f"ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø©: {tag.name}")
        
        db.session.commit()
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(NEWS_TAGS)} Ø¹Ù„Ø§Ù…Ø© Ø£Ø®Ø¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {str(e)}")
        db.session.rollback()
        raise


def load_sample_news():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©"""
    try:
        logger.info("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
        
        for news_data in SAMPLE_NEWS:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø®Ø¨Ø±
            existing = NewsItem.query.filter_by(slug=news_data['slug']).first()
            if not existing:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØµÙ†ÙŠÙ
                category = NewsCategory.query.filter_by(name=news_data['category_name']).first()
                if not category:
                    logger.warning(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØªØµÙ†ÙŠÙ: {news_data['category_name']}")
                    continue
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø¨Ø±
                news_item = NewsItem(
                    title=news_data['title'],
                    title_en=news_data.get('title_en'),
                    slug=news_data['slug'],
                    summary=news_data['summary'],
                    summary_en=news_data.get('summary_en'),
                    content=news_data['content'],
                    category_id=category.id,
                    status='published' if news_data['is_published'] else 'draft',
                    is_published=news_data['is_published'],
                    is_featured=news_data.get('is_featured', False),
                    is_breaking=news_data.get('is_breaking', False),
                    priority=news_data.get('priority', 0),
                    author_name=news_data.get('author_name'),
                    view_count=news_data.get('view_count', 0),
                    like_count=news_data.get('like_count', 0),
                    share_count=news_data.get('share_count', 0),
                    published_at=news_data.get('published_at'),
                    meta_title=news_data['title'],
                    meta_description=news_data['summary']
                )
                
                db.session.add(news_item)
                db.session.flush()  # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ID
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª
                if 'tags' in news_data:
                    for tag_name in news_data['tags']:
                        tag = NewsTag.query.filter_by(name=tag_name).first()
                        if tag:
                            news_item.tags.append(tag)
                            tag.usage_count += 1
                
                logger.info(f"ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø®Ø¨Ø±: {news_item.title}")
        
        db.session.commit()
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(SAMPLE_NEWS)} Ø®Ø¨Ø± ØªØ¬Ø±ÙŠØ¨ÙŠ Ø¨Ù†Ø¬Ø§Ø­")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©: {str(e)}")
        db.session.rollback()
        raise


def load_sample_comments():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©"""
    try:
        logger.info("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
        
        for comment_data in SAMPLE_COMMENTS:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø®Ø¨Ø±
            news_item = NewsItem.query.filter_by(slug=comment_data['news_slug']).first()
            if not news_item:
                logger.warning(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø¨Ø±: {comment_data['news_slug']}")
                continue
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚
            existing = NewsComment.query.filter_by(
                news_item_id=news_item.id,
                user_email=comment_data['user_email'],
                content=comment_data['content']
            ).first()
            
            if not existing:
                comment = NewsComment(
                    news_item_id=news_item.id,
                    user_name=comment_data['user_name'],
                    user_email=comment_data['user_email'],
                    content=comment_data['content'],
                    is_approved=comment_data.get('is_approved', False),
                    approved_at=datetime.utcnow() if comment_data.get('is_approved') else None
                )
                
                db.session.add(comment)
                
                # ØªØ­Ø¯ÙŠØ« Ø¹Ø¯Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙÙŠ Ø§Ù„Ø®Ø¨Ø±
                if comment.is_approved:
                    news_item.comment_count += 1
                
                logger.info(f"ØªÙ… Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ‚ Ù…Ù†: {comment.user_name}")
        
        db.session.commit()
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(SAMPLE_COMMENTS)} ØªØ¹Ù„ÙŠÙ‚ ØªØ¬Ø±ÙŠØ¨ÙŠ Ø¨Ù†Ø¬Ø§Ø­")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©: {str(e)}")
        db.session.rollback()
        raise


def load_news_settings():
    """ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
    try:
        logger.info("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…...")
        
        for setting_data in NEWS_SETTINGS:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯
            existing = NewsSettings.query.filter_by(setting_key=setting_data['setting_key']).first()
            if not existing:
                setting = NewsSettings(
                    setting_key=setting_data['setting_key'],
                    setting_value=setting_data['setting_value'],
                    setting_type=setting_data['setting_type'],
                    description=setting_data['description'],
                    category=setting_data['category'],
                    is_public=setting_data.get('is_public', False)
                )
                db.session.add(setting)
                logger.info(f"ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¥Ø¹Ø¯Ø§Ø¯: {setting.setting_key}")
        
        db.session.commit()
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(NEWS_SETTINGS)} Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…: {str(e)}")
        db.session.rollback()
        raise


def load_sample_stats():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©"""
    try:
        logger.info("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
        
        for stat_data in SAMPLE_STATS:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©
            existing = NewsStats.query.filter_by(
                news_item_id=stat_data['news_item_id'],
                date=stat_data['date']
            ).first()
            
            if not existing:
                stat = NewsStats(
                    news_item_id=stat_data['news_item_id'],
                    date=stat_data['date'],
                    views=stat_data['views'],
                    unique_views=stat_data['unique_views'],
                    likes=stat_data['likes'],
                    shares=stat_data['shares'],
                    comments=stat_data['comments'],
                    avg_read_time=stat_data['avg_read_time'],
                    bounce_rate=stat_data['bounce_rate'],
                    engagement_rate=stat_data['engagement_rate'],
                    direct_visits=stat_data['direct_visits'],
                    social_visits=stat_data['social_visits'],
                    search_visits=stat_data['search_visits'],
                    referral_visits=stat_data['referral_visits']
                )
                db.session.add(stat)
        
        db.session.commit()
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(SAMPLE_STATS)} Ø¥Ø­ØµØ§Ø¦ÙŠØ© ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©: {str(e)}")
        db.session.rollback()
        raise


def load_all_initial_data():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
    try:
        logger.info("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØµØ­ÙŠØ­
        load_news_categories()
        load_news_tags()
        load_sample_news()
        load_sample_comments()
        load_news_settings()
        load_sample_stats()
        
        logger.info("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­! âœ…")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ
        categories_count = NewsCategory.query.count()
        tags_count = NewsTag.query.count()
        news_count = NewsItem.query.count()
        comments_count = NewsComment.query.count()
        settings_count = NewsSettings.query.count()
        stats_count = NewsStats.query.count()
        
        logger.info(f"""
ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©:
- Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª: {categories_count}
- Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª: {tags_count}
- Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {news_count}
- Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª: {comments_count}
- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {settings_count}
- Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {stats_count}
        """)
        
        return True
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {str(e)}")
        return False


if __name__ == '__main__':
    # ØªØ´ØºÙŠÙ„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    load_all_initial_data()
